# general
output_file: "log/see_et_al.tar"
iterations: 230000
batch_size: 16
early_stopping: false
validator: "loss"
validate_every: 0 # every epoch
attn_model: "bahdanau"
coverage: false

# data config
vocab_file: "data/cnndm_abisee.vocab"
train_file: "data/cnndm_abisee_train.tsv"
valid_file: "data/cnndm_abisee_dev.tsv"

# hyper params
rnn_cell: "lstm"
vocab_size: 50000
hidden_size: 256
embed_size: 128
coverage_loss_weight: 1.0
attn_feature_size: 512
output_activation: null

# optimizing
optimizer: "adagrad"
learning_rate: 0.15
adagrad_init_acc: 0.1
max_grad_norm: 2.0

# test cfg
beam_size: 4
min_decode_steps: 35
max_decode_steps: 120
length_normalize: "avg"
